{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "621af092",
   "metadata": {},
   "source": [
    "Climate resiliance and risk managment Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d072b3",
   "metadata": {},
   "source": [
    "Installation of pacjages that will be needed for this model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70543494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63696cd7",
   "metadata": {},
   "source": [
    "Class for all Risk assessment Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35706e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseRiskModel:\n",
    "    def __init__(self, model_name, model_type='classification'):\n",
    "        self.model_name = model_name\n",
    "        self.model_type = model_type\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_selector = None\n",
    "        self.is_trained = False\n",
    "        self.features = None\n",
    "        self.training_history = []\n",
    "        self.model_params = {}\n",
    "\n",
    "    def prepare_data(self, data):\n",
    "        \"\"\"Prepare data for model training/prediction\"\"\"\n",
    "        raise NotImplementedError(\"Must implement prepare_data method\")   \n",
    "    \n",
    "    def train(self, X, y):\n",
    "        \"\"\"Train the risk model\"\"\"\n",
    "        raise NotImplementedError(\"Must implement train method\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make risk predictions\"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Get prediction probabilities\"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        if hasattr(self.model, 'predict_proba'):\n",
    "            return self.model.predict_proba(X)\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"Evaluate model performance\"\"\"\n",
    "        predictions = self.predict(X_test)\n",
    "        probabilities = self.predict_proba(X_test)\n",
    "        \n",
    "        evaluation = {\n",
    "            'accuracy': accuracy_score(y_test, predictions),\n",
    "            'classification_report': classification_report(y_test, predictions),\n",
    "            'confusion_matrix': confusion_matrix(y_test, predictions).tolist(),\n",
    "            'model_name': self.model_name,\n",
    "            'test_samples': len(X_test),\n",
    "            'evaluation_date': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        # Add AUC score if probabilities available\n",
    "        if probabilities is not None and len(np.unique(y_test)) == 2:\n",
    "            evaluation['auc_score'] = roc_auc_score(y_test, probabilities[:, 1])\n",
    "        \n",
    "        return evaluation\n",
    "    \n",
    "    def save_model(self, filepath):\n",
    "        \"\"\"Save trained model to file\"\"\"\n",
    "        model_data = {\n",
    "            'model': self.model,\n",
    "            'scaler': self.scaler,\n",
    "            'feature_selector': self.feature_selector,\n",
    "            'model_name': self.model_name,\n",
    "            'model_type': self.model_type,\n",
    "            'features': self.features,\n",
    "            'is_trained': self.is_trained,\n",
    "            'training_history': self.training_history,\n",
    "            'model_params': self.model_params,\n",
    "            'save_date': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        filepath = Path(filepath)\n",
    "        if filepath.suffix == '.pkl':\n",
    "            with open(filepath, 'wb') as f:\n",
    "                pickle.dump(model_data, f)\n",
    "        elif filepath.suffix == '.joblib':\n",
    "            joblib.dump(model_data, filepath)\n",
    "        \n",
    "        print(f\"Model saved to: {filepath}\")\n",
    "    \n",
    "    def load_model(self, filepath):\n",
    "        \"\"\"Load trained model from file\"\"\"\n",
    "        filepath = Path(filepath)\n",
    "        if filepath.suffix == '.pkl':\n",
    "            with open(filepath, 'rb') as f:\n",
    "                model_data = pickle.load(f)\n",
    "        elif filepath.suffix == '.joblib':\n",
    "            model_data = joblib.load(filepath)\n",
    "        \n",
    "        self.model = model_data['model']\n",
    "        self.scaler = model_data.get('scaler', StandardScaler())\n",
    "        self.feature_selector = model_data.get('feature_selector', None)\n",
    "        self.model_name = model_data['model_name']\n",
    "        self.model_type = model_data['model_type']\n",
    "        self.features = model_data['features']\n",
    "        self.is_trained = model_data['is_trained']\n",
    "        self.training_history = model_data.get('training_history', [])\n",
    "        self.model_params = model_data.get('model_params', {})\n",
    "        \n",
    "        print(f\"Model loaded from: {filepath}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b087b5",
   "metadata": {},
   "source": [
    "LANDSLIDE RISK MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3344dde",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
